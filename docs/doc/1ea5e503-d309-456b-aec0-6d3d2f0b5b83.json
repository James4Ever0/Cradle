{
    "summary": "The code handles game management and error logging, using libraries such as OpenCV for image manipulation and template-based icon replacement. It captures screenshots and extracts relevant information to perform the desired actions.",
    "details": [
        {
            "comment": "This code is defining a function `pause_game()` that pauses the game by pressing 'esc' and waiting for the pause screen to load, and another function `unpause_game()` that resumes the game if it was previously paused. It also centers the mouse location on the x-axis while the game is paused to avoid clipping at the game window border.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":0-43",
            "content": "import os, math\nimport time\nfrom typing import Any\nimport pydirectinput\nimport pyautogui\nfrom PIL import Image, ImageDraw, ImageFont\nimport cv2\nimport numpy as np\nimport torch\nfrom torchvision.ops import box_convert\nimport supervision as sv\nimport mss\nimport mss.tools\nfrom MTM import matchTemplates\nfrom cradle.config import Config\nfrom cradle.log import Logger\nfrom cradle.gameio import IOEnvironment\nfrom cradle.utils.template_matching import match_template_image\nconfig = Config()\nlogger = Logger()\nio_env = IOEnvironment()\nPAUSE_SCREEN_WAIT = 1\ndef pause_game():\n    if not is_env_paused():\n        io_env.handle_hold_in_pause()\n        pydirectinput.press('esc')\n        time.sleep(PAUSE_SCREEN_WAIT)\n    else:\n        logger.debug(\"The environment does not need to be paused!\")\n    # While game is paused, quickly re-center mouse location on x axis to avoid clipping at game window border with time\n    io_env.mouse_move(config.game_resolution[0] // 2, config.game_resolution[1] // 2, relative=False)\ndef unpause_game():\n    if is_env_paused():"
        },
        {
            "comment": "The code contains several methods to handle game environment pausing and resuming. `exit_back_to_pause()` tries to pause the game by repeatedly pressing 'esc', with a maximum of 10 attempts. If it fails, it logs a warning. `exit_back_to_game()` first calls `exit_back_to_pause()` and then unpauses the game using `unpause_game()`. `switch_to_game()` tries to switch to the game window by activating it if its title matches the expected name in the config file. If not found or any exception occurs, it logs an error.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":44-85",
            "content": "        pydirectinput.press('esc')\n        time.sleep(PAUSE_SCREEN_WAIT)\n        io_env.handle_hold_in_unpause()\n    else:\n        logger.debug(\"The environment is not paused!\")\ndef exit_back_to_pause():\n    max_steps = 10\n    back_steps = 0\n    while not is_env_paused() and back_steps < max_steps:\n        back_steps += 1\n        pydirectinput.press('esc')\n        time.sleep(PAUSE_SCREEN_WAIT)\n    if back_steps >= max_steps:\n        logger.warn(\"The environment fails to pause!\")\ndef exit_back_to_game():\n    exit_back_to_pause()\n    # Unpause the game, to keep the rest of the agent flow consistent\n    unpause_game()\ndef switch_to_game():\n    named_windows = pyautogui.getWindowsWithTitle(config.env_name)\n    if len(named_windows) == 0:\n        logger.error(f\"Cannot find the game window {config.env_name}!\")\n        return\n    else:\n        try:\n            named_windows[0].activate()\n        except Exception as e:\n            if \"Error code from Windows: 0\" in str(e):\n                # Handle pygetwindow exception\n                pass"
        },
        {
            "comment": "The code defines a function `take_screenshot` that captures screenshots of the specified game region and optionally the minimap. It saves the screen and minimap images in the output directory with timestamps appended to filenames. The function raises exceptions if there are errors during screenshot capture. It uses the mss library for screen grabbing and Pillow module for image processing.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":86-123",
            "content": "            else:\n                raise e\n    time.sleep(1)\n    unpause_game()\n    time.sleep(1)\ndef take_screenshot(tid : float = 0.0,\n                    screen_region : tuple[int, int, int, int] = config.game_region,\n                    minimap_region : tuple[int, int, int, int] = config.minimap_region,\n                    include_minimap = True,\n                    draw_axis = False):\n    region = screen_region\n    region = {\n        \"left\": region[0],\n        \"top\": region[1],\n        \"width\": region[2],\n        \"height\": region[3],\n    }\n    output_dir = config.work_dir\n    # Save screenshots\n    screen_image_filename = output_dir + \"/screen_\" + str(tid) + \".jpg\"\n    with mss.mss() as sct:\n        screen_image = sct.grab(region)\n        image = Image.frombytes(\"RGB\", screen_image.size, screen_image.bgra, \"raw\", \"BGRX\")\n        image.save(screen_image_filename)\n    minimap_image_filename = \"\"\n    if include_minimap:\n        minimap_image_filename = output_dir + \"/minimap_\" + str(tid) + \".jpg\"\n        mm_region = minimap_region"
        },
        {
            "comment": "This code captures a minimap image from the screen, saves it to file, and then draws axes on the main screenshot. The captured minimap is obtained using the mss library, with region specified by mm_region variable. The main screenshot's image is manipulated for drawing axes and text labels at various positions.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":124-154",
            "content": "        mm_region = {\n            \"left\": mm_region[0],\n            \"top\": mm_region[1],\n            \"width\": mm_region[2],\n            \"height\": mm_region[3],\n        }\n        with mss.mss() as sct:\n            minimap_image = sct.grab(mm_region)\n            mm_image = Image.frombytes(\"RGB\", minimap_image.size, minimap_image.bgra, \"raw\", \"BGRX\")\n            mm_image.save(minimap_image_filename)\n        clip_minimap(minimap_image_filename)\n    if draw_axis:\n        # Draw axis on the screenshot\n        draw = ImageDraw.Draw(screen_image)\n        width, height = screen_image.size\n        cx, cy = width // 2, height // 2\n        draw.line((cx, 0, cx, height), fill=\"blue\", width=3)  # Y\n        draw.line((0, cy, width, cy), fill=\"blue\", width=3)  # X\n        font = ImageFont.truetype(\"arial.ttf\", 30)\n        offset_for_text = 30\n        interval = 0.1\n        for i in range(10):\n            if i > 0:\n                draw.text((cx + interval * (i ) * width // 2, cy), str(i ), fill=\"blue\", font = font)\n                draw.text((cx - interval * (i) * width // 2, cy), str(-i), fill=\"blue\", font = font)"
        },
        {
            "comment": "This code segment saves a screenshot, crops the minimap region from it, and creates axes images by drawing positive and negative numbers. It uses the OpenCV library for image manipulation.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":155-179",
            "content": "                draw.text((cx - offset_for_text - 10, cy + interval * (i ) * height // 2), str(-i), fill=\"blue\", font = font)\n            draw.text((cx - offset_for_text, cy - interval * (i ) * height // 2), str(i), fill=\"blue\", font = font)\n        axes_image_filename = output_dir + \"/axes_screen_\" + str(tid) + \".jpg\"\n        screen_image.save(axes_image_filename)\n    return screen_image_filename, minimap_image_filename\ndef segment_minimap(screenshot_path):\n    tid = time.time()\n    output_dir = config.work_dir\n    minimap_image_filename = output_dir + \"/minimap_\" + str(tid) + \".jpg\"\n    minimap_region = config.base_minimap_region\n    minimap_region = [int(x * (config.game_resolution[0] / config.base_resolution[0]) ) for x in minimap_region] # (56, 725, 56 + 320, 725 + 320)\n    minimap_region[2] += minimap_region[0]\n    minimap_region[3] += minimap_region[1]\n    # Open the source image file\n    with Image.open(screenshot_path) as source_image:\n        # Crop the image using the crop_rectangle\n        cropped_minimap = source_image.crop(minimap_region)"
        },
        {
            "comment": "The code checks if the game is paused by comparing the confidence score from matching a pause clock template image with the current screenshot. It saves the cropped minimap to a new file and renames the pause candidate screenshot for debugging or gameplay scenarios.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":181-213",
            "content": "        # Save the cropped image to a new file\n        cropped_minimap.save(minimap_image_filename)\n    clip_minimap(minimap_image_filename)\n    return minimap_image_filename\ndef is_env_paused():\n    is_paused = False\n    confidence_threshold = 0.85\n    # Multiple-scale-template-matching example, decide whether the game is paused according to the confidence score\n    pause_clock_template_file = './res/icons/clock.jpg'\n    screenshot = take_screenshot(time.time(), include_minimap=False)[0]\n    match_info = match_template_image(screenshot, pause_clock_template_file, debug=True, output_bb=True, save_matches=True, scale='full')\n    is_paused = match_info[0]['confidence'] >= confidence_threshold\n    # Renaming pause candidate screenshot to ease debugging or gameplay scenarios\n    os.rename(screenshot, screenshot.replace('screen', 'pause_screen_candidate'))\n    return is_paused\ndef clip_minimap(minimap_image_filename):\n    image = cv2.imread(minimap_image_filename)\n    # Get the dimensions of the image\n    height, width = image.shape[:2]"
        },
        {
            "comment": "The code generates a mask for an image with black triangles at each corner, applies the mask to the image, and saves the result. The function takes image source, bounding boxes, logits, and phrases as inputs and seems to be part of an annotation process.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":215-241",
            "content": "    # Create a mask of the same size as the image, initialized to white\n    mask = np.ones((height, width, 3), dtype=np.uint8) * 255\n    # Define the size of the triangular mask at each corner\n    triangle_size = int(180 * config.resolution_ratio)\n    # Draw black triangles on the four corners of the mask\n    # Top-left corner\n    cv2.fillConvexPoly(mask, np.array([[0, 0], [triangle_size, 0], [0, triangle_size]]), 0)\n    # Top-right corner\n    cv2.fillConvexPoly(mask, np.array([[width, 0], [width - triangle_size, 0], [width, triangle_size]]), 0)\n    # Bottom-left corner\n    cv2.fillConvexPoly(mask, np.array([[0, height], [0, height - triangle_size], [triangle_size, height]]), 0)\n    # Bottom-right corner\n    cv2.fillConvexPoly(mask, np.array([[width, height], [width, height - triangle_size], [width - triangle_size, height]]), 0)\n    # Apply the mask to the image\n    masked_image = cv2.bitwise_and(image, mask)\n    # Save the result\n    cv2.imwrite(minimap_image_filename, masked_image)\ndef annotate_with_coordinates(image_source, boxes, logits, phrases):"
        },
        {
            "comment": "Code takes an image, detects objects within it using a Detections class, and annotates the image with box labels indicating object positions. The code also initializes a CircleDetector instance for potential future super resolution processing based on the input's resolution ratio.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":242-267",
            "content": "    h, w, _ = image_source.shape\n    boxes = boxes * torch.Tensor([w, h, w, h])\n    xyxy = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n    logger.debug(f\"boxes: {boxes}, xyxy: {xyxy}\")\n    detections = sv.Detections(xyxy=xyxy)\n    # Without coordinates normalization\n    labels = [\n        f\"{phrase} {' '.join(map(str, ['x=', round((xyxy_s[0]+xyxy_s[2])/(2*w), 2), ', y=', round((xyxy_s[1]+xyxy_s[3])/(2*h), 2)]))}\"\n        for phrase, xyxy_s\n        in zip(phrases, xyxy)\n    ]\n    box_annotator = sv.BoxAnnotator()\n    annotated_frame = cv2.cvtColor(image_source, cv2.COLOR_RGB2BGR)\n    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n    return annotated_frame\nclass CircleDetector:\n    def __init__(self,resolution_ratio):\n        if resolution_ratio <= .67:  # need super resolution\n            self.sr_model = cv2.dnn_superres.DnnSuperResImpl_create()\n            self.k = 2 if resolution_ratio <=.5 else 3\n            self.sr_model.readModel(f'./res/models/ESPCN_x{self.k}.pb')"
        },
        {
            "comment": "The code snippet appears to be from a computer vision script used for image processing. It contains a method for applying super resolution based on a given model, determining the angle between two points using the atan2 function and converting it to degrees, and a detect method that reads an image file and applies color filters to detect yellow, gray, or red objects in the image. The code also takes in optional parameters for setting the detection mode (yellow & gray or just yellow) and a debug flag.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":268-292",
            "content": "            self.sr_model.setModel('espcn', self.k)\n        else:\n            self.sr_model = None\n    def get_theta(self, origin_x, origin_y, center_x, center_y):\n        '''\n        The origin of the image coordinate system is usually located in the upper left corner of the image, with the x-axis to the right indicating a positive direction and the y-axis to the down indicating a positive direction. Using vertical upward as the reference line, i.e. the angle between it and the negative direction of the y-axis\n        '''\n        theta = math.atan2(center_x - origin_x, origin_y - center_y)\n        theta = math.degrees(theta)\n        return theta\n    def detect(self, img_file,\n        yellow_range=np.array([[140, 230, 230], [170, 255, 255]]),\n        gray_range=np.array([[165, 165, 165], [175, 175, 175]]),\n        red_range=np.array([[0, 0, 170], [30, 30, 240]]),\n        detect_mode='yellow & gray',\n        debug=False\n    ):\n        image = cv2.imread(img_file)\n        # super resolution according to resolution ratio"
        },
        {
            "comment": "Performing image resizing, upsampling and converting to grayscale before applying Hough transform for detecting circles in the image.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":293-316",
            "content": "        if self.sr_model is not None:\n            image = self.sr_model.upsample(image)\n            if self.k == 3:\n                image = cv2.resize(image, (0, 0), fx=0.5, fy=0.5)\n        origin = (image.shape[0] // 2, image.shape[1] // 2)\n        circles = cv2.HoughCircles(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.HOUGH_GRADIENT, 1, 10, param1=200,param2=10, minRadius=5 * 2, maxRadius=8 * 2)\n        theta = 0x3f3f3f3f\n        measure = {'theta': theta, 'distance': theta, 'color': np.array([0, 0, 0]), 'confidence': 0, 'vis': image,\n                   'center': origin}\n        circles_info = []\n        if circles is not None:\n            circles = np.round(circles[0, :]).astype(\"int\")\n            for (x, y, r) in circles:\n                # Crop the circle from the original image\n                circle_img = np.zeros_like(image)\n                cv2.circle(circle_img, (x, y), r, (255, 255, 255), thickness=-1)\n                circle = cv2.bitwise_and(image, circle_img)\n                # Define range for red color and create a mask"
        },
        {
            "comment": "This code segment uses OpenCV to apply masks for red, gray, and yellow colors on a circle image. It counts non-zero pixels in each mask and stores the circle's center, radius, and color count information in a list. The circles are then sorted based on their red, yellow, and gray pixel counts in descending order if 'red' is specified in detect_mode.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":317-337",
            "content": "                red_mask = cv2.inRange(circle, red_range[0], red_range[1])\n                gray_mask = cv2.inRange(circle, gray_range[0], gray_range[1])\n                yellow_mask = cv2.inRange(circle, yellow_range[0], yellow_range[1])\n                # Count red pixels in the circle\n                red_count = cv2.countNonZero(red_mask)\n                gray_count = cv2.countNonZero(gray_mask)\n                yellow_count = cv2.countNonZero(yellow_mask)\n                # Add circle information and color counts to the list\n                circles_info.append({\n                    \"center\": (x, y),\n                    \"radius\": r,\n                    \"red_count\": red_count,\n                    \"gray_count\": gray_count,\n                    \"yellow_count\": yellow_count\n                })\n            # Sort the circles based on yellow_count, gray_count, and red_count\n            if 'red' in detect_mode:\n                circles_info.sort(key=lambda c: (c['red_count'], c['yellow_count'], c['gray_count']), reverse=True)"
        },
        {
            "comment": "Checks if a circle has at least 5 yellow or gray counts, then sorts circles by those counts in descending order. If a circle meets the detection criterion, it creates a measure object with its theta, distance, color (gray or yellow), confidence, and bounding box coordinates.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":338-353",
            "content": "                detect_criterion = lambda circle: circle[\"red_count\"] >= 5\n            else:\n                circles_info.sort(key=lambda c: (c['yellow_count'], c['gray_count'], c['red_count']), reverse=True)\n                detect_criterion = lambda circle: circle[\"gray_count\"] >= 5 or circle[\"yellow_count\"] >= 5\n            for circle in circles_info:\n                center_x, center_y, radius = circle[\"center\"][0], circle[\"center\"][1], circle[\"radius\"]\n                if detect_criterion(circle):\n                    theta = self.get_theta(*origin, center_x, center_y)\n                    dis = np.sqrt((center_x - origin[0]) ** 2 + (center_y - origin[1]) ** 2)\n                    measure = {'theta': theta, 'distance': dis,\n                               'color': \"yellow\" if circle[\"yellow_count\"] >= 5 else \"gray\", 'confidence': 1,\n                               'center': (center_x, center_y),\n                               'bounding_box': (center_x - radius, center_y - radius, 2 * radius, 2 * radius)}"
        },
        {
            "comment": "This code defines a class IconReplacer that replaces icons in an image using templates. The constructor takes a template path and lists all files in the directory. The __call__ method takes a list of image paths and returns the result of replace_icon method. The _drawBoxesOnRGB method is used to draw bounding boxes on the image with predicted template locations.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":354-377",
            "content": "                    break\n            if debug:\n                for i, circle in enumerate(circles_info):\n                    cv2.circle(image, circle[\"center\"], circle[\"radius\"], (0, 255, 0), 2)\n                    cv2.putText(image, str(i + 1), (circle[\"center\"][0] - 5, circle[\"center\"][1] + 4),\n                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n                measure['vis'] = image\n        return theta, measure\nclass IconReplacer:\n    def __init__(self, template_path = './res/icons/keys'):\n        self.template_paths = [os.path.join(template_path, filename) for filename in os.listdir(template_path)]\n    def __call__(self, image_paths):\n        return self.replace_icon(image_paths)\n    def _drawBoxesOnRGB(self, image, tableHit, boxThickness=2, boxColor=(255, 255, 00), showLabel=False, labelColor=(255, 255, 0), labelScale=0.5):\n        \"\"\"\n        Return a copy of the image with predicted template locations as bounding boxes overlaid on the image\n        The name of the template can also be displayed on top of the bounding box with showLabel=True"
        },
        {
            "comment": "This code snippet defines a function that takes an image, hit list, box thickness, box color, show label flag, and label color as input. It returns the original image with predicted template locations depicted as bounding boxes. If the image is grayscale, it converts to RGB for visualization purposes before iterating over the hit list to draw bounding boxes on the image.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":379-407",
            "content": "        Parameters\n        ----------\n        - image  : image in which the search was performed\n        - tableHit: list of hit as returned by matchTemplates or findMatches\n        - boxThickness: int\n                        thickness of bounding box contour in pixels\n        - boxColor: (int, int, int)\n                    RGB color for the bounding box\n        - showLabel: Boolean\n                    Display label of the bounding box (field TemplateName)\n        - labelColor: (int, int, int)\n                    RGB color for the label\n        Returns\n        -------\n        outImage: RGB image\n                original image with predicted template locations depicted as bounding boxes\n        \"\"\"\n        # Convert Grayscale to RGB to be able to see the color bboxes\n        if image.ndim == 2:\n            outImage = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) # convert to RGB to be able to show detections as color box on grayscale image\n        else:\n            outImage = image.copy()\n        for _, row in tableHit.iterrows():"
        },
        {
            "comment": "This code snippet calculates the bounding box coordinates and dimensions for a template image on an input image. It then draws the bounding box using cv2.rectangle() and adds text on top of the bounding box using cv2.putText(). The _get_mtm_match function performs non-maximum suppression (NMS) to find the best match for each template in the given input image.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":409-427",
            "content": "            x,y,w,h = row['BBox']\n            text = row['TemplateName']\n            if showLabel:\n                text_size, baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_DUPLEX, labelScale, 1)\n                text_width, text_height = text_size\n                rectangle_pos = [(int(x - 0.2 * w), int(y - 0.15 * h)), (int(x + 1.2 * w), int(y + 1.05 * h))]\n                cv2.rectangle(outImage, rectangle_pos[0], rectangle_pos[1], color=boxColor, thickness=-1)\n                text_x = int((rectangle_pos[0][0] + rectangle_pos[1][0]) / 2 - text_width / 2)\n                text_y = int((rectangle_pos[0][1] + rectangle_pos[1][1]) / 2 + text_height / 2)\n                cv2.putText(outImage, text=text, org=(text_x, text_y), fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=labelScale, color=labelColor, lineType=cv2.LINE_AA,thickness=1)\n        return outImage\n    def _get_mtm_match(self, image: np.ndarray, template: np.ndarray, template_name):\n        detection = matchTemplates([(template_name, cv2.resize(template, (round(template.shape[1] * s), round(template.shape[0] * s)))) for s in [0.9, 1, 1.1]],"
        },
        {
            "comment": "This code detects and draws objects on an image based on the detection score. If the score is above 0.75, it displays a box around the detected object. The code also includes functions to show or save the image, as well as image augmentation for VLM issues by replacing specific icons in the images.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":428-458",
            "content": "                                image,\n                                N_object=1,\n                                method=cv2.TM_CCOEFF_NORMED,\n                                maxOverlap=0.1)\n        if detection['Score'].iloc[0] > 0.75:\n            image = self._drawBoxesOnRGB(image, detection, boxThickness=-1, showLabel=True, boxColor=(255, 255, 255), labelColor=(0, 0, 0), labelScale=.62)\n        return {'info': detection, 'vis': image}\n    def _show(self, image, window_name='screen',show=True,save=''):\n        if save:\n            cv2.imwrite(save, image)\n        if show:\n            cv2.namedWindow(window_name, 0)\n            cv2.imshow(window_name, image)\n            cv2.waitKey(0)\n            cv2.destroyAllWindows()\n    # Image augmentation to mitigate VLM issues\n    def replace_icon(self, image_paths):\n        replaced_image_paths = []\n        for image_path in image_paths:\n            image = cv2.imread(image_path)\n            for template_file in self.template_paths:\n                template = cv2.imread(template_file)"
        },
        {
            "comment": "This code extracts an image path and determines the template name based on specific keywords. It then replaces the image with a template-specific identifier and saves it to a new path. The replaced image paths are added to a list, which is returned at the end.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/gameio/lifecycle/ui_control.py\":459-480",
            "content": "                template_name = os.path.splitext(os.path.basename(template_file))[0]\n                if 'left_mouse' in template_name:\n                    template_name = 'LM'\n                elif 'right_mouse' in template_name:\n                    template_name = 'RM'\n                elif 'mouse' in template_name:\n                    template_name = 'MS'\n                elif 'enter' in template_name:\n                    template_name = 'Ent'\n                detection = self._get_mtm_match(image, template, template_name)\n                image = detection['vis']\n            directory, filename = os.path.split(image_path)\n            save_path = os.path.join(directory, \"icon_replace_\"+filename)\n            self._show(image, save=save_path, show=False)\n            replaced_image_paths.append(save_path)\n        return replaced_image_paths"
        }
    ]
}