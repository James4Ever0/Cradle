{
    "summary": "This code compares two minimap images for movement by reading in the images, creating ORB features, matching descriptors, and determining if a threshold is exceeded based on average distance.",
    "details": [
        {
            "comment": "The code is for image processing and comparison, specifically detecting movement between two minimap images. It reads in the images, creates ORB features, and compares the keypoints to determine if a movement threshold has been exceeded.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/image_utils.py\":0-32",
            "content": "import numpy as np\nimport cv2\nfrom cradle.config import Config\nconfig = Config()\ndef show_image(img):\n    if isinstance(img, str):\n        img = cv2.imread(img)\n    cv2.namedWindow(\"display\", cv2.WINDOW_NORMAL)\n    cv2.imshow(\"display\", img)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\ndef minimap_movement_detection(image_path1, image_path2, threshold = 30):\n    '''\n    Detect whether two minimaps are the same to determine whether the character moves successfully.\n    Args:\n        image_path1, image_path2: 2 minimap images to be detected.\n        threshold: pixel-level threshold for minimap movement detection, default 30.\n    Returns:\n        change_detected: True if the movements is above the threshold,\n        img_matches: Draws the found matches of keypoints from two images. Can be visualized by plt.imshow(img_matches)\n    '''\n    img1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n    img2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n    orb = cv2.ORB_create()\n    keypoints1, descriptors1 = orb.detectAndCompute(img1, None)"
        },
        {
            "comment": "This code detects and computes keypoints and descriptors for two images using ORB algorithm, matches the descriptors using BFMatcher, draws top 20 matches on the images, calculates average distance, and determines if a change is detected based on the average distance and threshold.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/image_utils.py\":33-49",
            "content": "    keypoints2, descriptors2 = orb.detectAndCompute(img2, None)\n    if type(descriptors1) != type(None) and type(descriptors2) != type(None):\n        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n        matches = bf.match(descriptors1, descriptors2)\n    else:\n        return True, None, None\n    matches = sorted(matches, key = lambda x:x.distance)\n    img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches[:20], None, flags=2)\n    best_matches = matches[:20]\n    average_distance = np.mean([m.distance for m in best_matches])\n    change_detected = average_distance > (threshold * config.resolution_ratio) or np.allclose(average_distance, 0, atol=1e-3)\n    return change_detected, img_matches, average_distance"
        }
    ]
}