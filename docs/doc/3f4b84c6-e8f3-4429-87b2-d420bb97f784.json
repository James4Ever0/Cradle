{
    "summary": "This code uses a timing decorator with OpenCV template matching for image combining, scales and rotates images, measures detection time, and outputs results in various formats. It converts detection data into a list of dictionaries containing type, name, coordinates, confidence, and optional reasoning.",
    "details": [
        {
            "comment": "This code defines a function \"render\" that combines two images, overlay and template_image, into a single canvas. It also defines a decorator \"timing\" which measures the execution time of a decorated function. The render function can optionally save the result to a file and/or display it in a window.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/template_matching.py\":0-36",
            "content": "import os\nimport time\nfrom typing import List, Union\nimport cv2\nfrom MTM import matchTemplates, drawBoxesOnRGB\nimport numpy as np\nfrom cradle.config import Config\nfrom cradle.log import Logger\nfrom cradle.utils.file_utils import assemble_project_path\nfrom cradle.utils.json_utils import save_json\nconfig = Config()\nlogger = Logger()\ndef render(overlay, template_image, output_file_name='', view=False):\n    canvas_width = overlay.shape[1] + template_image.shape[1]\n    canvas_height = max(overlay.shape[0], template_image.shape[0])\n    canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n    canvas[:overlay.shape[0], :overlay.shape[1]] = overlay\n    canvas[:template_image.shape[0], overlay.shape[1]:overlay.shape[1] + template_image.shape[1]] = template_image\n    if output_file_name:\n        cv2.imwrite(output_file_name, canvas)\n    if view:\n        cv2.namedWindow('match result', 0)\n        cv2.imshow('match result', canvas)\n        cv2.waitKey(0)\n        cv2.destroyAllWindows()\ndef timing(func):\n    def wrapper(*args, **kwargs):"
        },
        {
            "comment": "This code contains a function for multi-scale template matching, taking an image and a template as input. It resizes the template to different scales, performs template matching using OpenCV's matchTemplates function, renames detection results based on confidence scores, and provides optional output in various formats depending on user parameters. The code also includes a timing decorator to measure execution time for each function call.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/template_matching.py\":37-60",
            "content": "        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        elapsed_time = end_time - start_time\n        logger.debug(f\"{func.__name__} consumes {elapsed_time:.4f}s\")\n        return result\n    return wrapper\n# @timing\ndef get_mtm_match(image: np.ndarray, template: np.ndarray, scales: list):\n    detection = matchTemplates([('', cv2.resize(template, (0, 0), fx=s, fy=s)) for s in scales], image, N_object=1, method=cv2.TM_CCOEFF_NORMED, maxOverlap=0.1)\n    detection['TemplateName'] = [str(round(i, 3)) for i in detection['Score']]  # confidence as name for display\n    return detection\ndef match_template_image(src_file: str, template_file: str, debug = False, output_bb = False, save_matches = False, scale = \"normal\", rotate_angle : float = 0) -> List[dict]:\n    '''\n    Multi-scale template matching\n    :param src_file: source image file\n    :param template_file: template image file\n    :param debug: output debug log messages\n    :param output_bb: output bounding boxes in json"
        },
        {
            "comment": "This function takes parameters for scaling and rotation of a source image, reads the image, and resizes the template based on the given resolution ratio. It also provides default options for scaling and raises a ValueError if an invalid argument is provided.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/template_matching.py\":61-87",
            "content": "    :param save_matches: save the matched image\n    :param scale: scale for template, default is 'normal', chosen from 'small', 'mid', 'normal', 'full', or you can also specify a list of float numbers\n    :param rotate_angle: angle for source image rotation, at the center of image, clockwise\n    :return:\n    objects_list, a list of dicts, including template name, bounding box and confidence.\n    '''\n    output_dir = config.work_dir\n    tid = time.time()\n    scales = scale\n    if scales == 'small':\n        scales = [0.1, 0.2, 0.3, 0.4, 0.5]\n    elif scales == 'mid':\n        scales = [0.3, 0.4, 0.5, 0.6, 0.7]\n    elif scales == 'normal':\n        scales = [0.8, 0.9, 1.0, 1.1, 1.2]\n    elif scales == 'full':\n        scales = [0.5,0.75,1.0,1.5,2]\n    elif not isinstance(scales, list):\n        raise ValueError('scales must be a list of float numbers or one of \"small\", \"mid\", \"normal\", \"full\"')\n    image = cv2.imread(assemble_project_path(src_file))\n    template = cv2.imread(assemble_project_path(template_file))\n    # Resize template according to resolution ratio"
        },
        {
            "comment": "Resizes template image based on resolution ratio and rotates the input image if necessary. Measures detection time, extracts template name and source name, creates output prefix. If matches are saved, draws bounding boxes and labels on overlay image and saves it with output prefix appended.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/template_matching.py\":88-113",
            "content": "    template = cv2.resize(template, (0, 0), fx=config.resolution_ratio, fy=config.resolution_ratio)\n    if rotate_angle != 0:\n        h, w, c = image.shape\n        M = cv2.getRotationMatrix2D((w // 2, h // 2), rotate_angle, 1)\n        image = cv2.warpAffine(image, M, (w, h))  # np.rot90\n    begin_detect_time = time.time()\n    detection = get_mtm_match(image, template, scales)\n    end_detect_time = time.time()\n    template_name = os.path.splitext(os.path.basename(template_file))[0]\n    source__name = os.path.splitext(os.path.basename(src_file))[0]\n    output_prefix = f'match_{str(tid)}_{template_name}_in_{source__name}'\n    if save_matches:\n        overlay = drawBoxesOnRGB(image, detection,\n                                 showLabel=True,\n                                 boxThickness=4,\n                                 boxColor=(0, 255, 0),\n                                 labelColor=(0, 255, 0),\n                                 labelScale=1)\n        overlay_file_path = os.path.join(output_dir, f'{output_prefix}_overlay.jpg')"
        },
        {
            "comment": "This code converts detection results into a list of dictionaries, with each dictionary containing the type, name, bounding box coordinates, reasoning (empty for now), value (set to 0), and confidence. It also logs debug information if necessary. If output_bb is True, it saves the objects_list as JSON in a specified file. It then returns the objects_list.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/utils/template_matching.py\":114-136",
            "content": "        render(overlay, template, overlay_file_path)\n    # DataFrame to list of dicts\n    objects_list = []\n    for bounding_box, confidence in zip(detection['BBox'], detection['Score']):\n        object_dict = {\n            \"type\":template_name,\n            \"name\": template_name,\n            \"bounding_box\": bounding_box,\n            \"reasoning\": \"\",\n            \"value\": 0,\n            \"confidence\": confidence,\n        }\n        objects_list.append(object_dict)\n        if debug:\n           logger.debug(f'{src_file}\\t{template_file}\\t{bounding_box}\\t{confidence}\\t{end_detect_time - begin_detect_time}',)\n    if output_bb:\n        bb_output_file = os.path.join(output_dir, f'{output_prefix}_bb.json')\n        save_json(bb_output_file, objects_list, 4)\n    return objects_list"
        }
    ]
}