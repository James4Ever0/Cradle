{
    "summary": "The code gathers parallel data, manages exceptions and logs progress. It extracts video info, processes data by sorting/removing redundancies, detects objects using asyncio event loop, and defines classes for object detection, LLM success detection, AI planner tasks. The code initializes modules for decision making and reflection, and generates prompts with planner function capabilities.",
    "details": [
        {
            "comment": "The code is importing necessary libraries, defining constants and functions for gathering information parallelly from frames using LLMProvider. The function takes llm_provider, text_input_map, current_frame_path, time_stamp, text_input, get_text_template, i (frame index), video_prefix and gathered_information_JSON as parameters to gather text information from the frame. It logs the progress of gathering text information. The text_input parameter is optional. The image_introduction is extracted from the text_input dictionary.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":0-30",
            "content": "import time\nimport json\nimport os\nfrom typing import Dict, Any, List\nimport time\nimport asyncio\nfrom cradle.config import Config\nfrom cradle.gameio.video.VideoFrameExtractor import JSONStructure\nfrom cradle.log import Logger\nfrom cradle.planner.base import BasePlanner\nfrom cradle.provider.base_llm import LLMProvider\nfrom cradle.utils.check import check_planner_params\nfrom cradle.utils.file_utils import assemble_project_path, read_resource_file\nfrom cradle.utils.json_utils import load_json, parse_semi_formatted_text\nfrom cradle import constants\nconfig = Config()\nlogger = Logger()\nPROMPT_EXT = \".prompt\"\nJSON_EXT = \".json\"\nasync def gather_information_get_completion_parallel(llm_provider, text_input_map, current_frame_path, time_stamp,\n                                                     text_input, get_text_template, i,video_prefix,gathered_information_JSON):\n    logger.write(f\"Start gathering text information from the {i + 1}th frame\")\n    text_input = text_input_map if text_input is None else text_input\n    image_introduction = text_input[\"image_introduction\"]"
        },
        {
            "comment": "The code sets the last frame path as current, updates text input and generates message prompts. It then tries to create a completion using llm_provider while handling exceptions if response format is incorrect.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":32-54",
            "content": "    # Set the last frame path as the current frame path\n    image_introduction[-1] = {\n        \"introduction\": image_introduction[-1][\"introduction\"],\n        \"path\": f\"{current_frame_path}\",\n        \"assistant\": image_introduction[-1][\"assistant\"]\n    }\n    text_input[\"image_introduction\"] = image_introduction\n    message_prompts = llm_provider.assemble_prompt(template_str=get_text_template, params=text_input)\n    logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n    success_flag = False\n    while not success_flag:\n        try:\n            response, info = await llm_provider.create_completion_async(message_prompts)\n            logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n            success_flag = True\n        except Exception as e:\n            logger.error(f\"Response is not in the correct format: {e}, retrying...\")\n            success_flag = False"
        },
        {
            "comment": "The code waits for 2 seconds, checks if the response is empty and logs a warning message if it is, converts the response to a dictionary, assigns a unique index based on video prefix and timestamp, adds the converted response to gathered_information_JSON, logs completion of gathering text information from the frame, and returns True. The function starts gathering text info for the current frame by checking if there's an existing text input, using the appropriate source, introduces the image with text input, and assigns unique index based on video prefix and timestamp.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":56-78",
            "content": "            # wait 2 seconds for the next request and retry\n            await asyncio.sleep(2)\n    # Convert the response to dict\n    if processed_response is None or len(response) == 0:\n        logger.warn('Empty response in gather text information call')\n        logger.debug(\"response\", response, \"processed_response\", processed_response)\n    objects = processed_response\n    objects_index = str(video_prefix) + '_' + time_stamp\n    gathered_information_JSON.add_instance(objects_index, objects)\n    logger.write(f\"Finish gathering text information from the {i + 1}th frame\")\n    return True\ndef gather_information_get_completion_sequence(llm_provider, text_input_map, current_frame_path, time_stamp,\n                                               text_input, get_text_template, i, video_prefix, gathered_information_JSON):\n    logger.write(f\"Start gathering text information from the {i + 1}th frame\")\n    text_input = text_input_map if text_input is None else text_input\n    image_introduction = text_input[\"image_introduction\"]"
        },
        {
            "comment": "Sets last frame path as current frame path. Retrieves text input and updates image_introduction list. Assembles prompt using llm_provider template and params, logs upstream message prompts. Creates completion using llm_provider, logs downstream response. Uses a loop to handle incorrect response format by parsing the semi-formatted text and retrying after 2 seconds if failed.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":80-105",
            "content": "    # Set the last frame path as the current frame path\n    image_introduction[-1] = {\n        \"introduction\": image_introduction[-1][\"introduction\"],\n        \"path\": f\"{current_frame_path}\",\n        \"assistant\": image_introduction[-1][\"assistant\"]\n    }\n    text_input[\"image_introduction\"] = image_introduction\n    message_prompts = llm_provider.assemble_prompt(template_str=get_text_template, params=text_input)\n    logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n    response, info = llm_provider.create_completion(message_prompts)\n    logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n    success_flag = False\n    while not success_flag:\n        try:\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n            success_flag = True\n        except Exception as e:\n            logger.error(f\"Response is not in the correct format: {e}, retrying...\")\n            success_flag = False\n            time.sleep(2)"
        },
        {
            "comment": "This code is defining a function called `get_completion_in_parallel` that takes in arguments like llm_provider, text_input_map, extracted_frame_paths, and other parameters. The function creates tasks for each frame path and time stamp pair in the extracted_frame_paths list. It appends these tasks to a list called 'tasks'.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":107-129",
            "content": "    # Convert the response to dict\n    if processed_response is None or len(response) == 0:\n        logger.warn('Empty response in gather text information call')\n        logger.debug(\"response\", response, \"processed_response\", processed_response)\n    objects = processed_response\n    objects_index = str(video_prefix) + '_' + time_stamp\n    gathered_information_JSON.add_instance(objects_index, objects)\n    logger.write(f\"Finish gathering text information from the {i + 1}th frame\")\n    return True\nasync def get_completion_in_parallel(llm_provider, text_input_map, extracted_frame_paths, text_input,get_text_template,video_prefix,gathered_information_JSON):\n    tasks =[]\n    for i, (current_frame_path, time_stamp) in enumerate(extracted_frame_paths):\n        task=gather_information_get_completion_parallel(llm_provider, text_input_map, current_frame_path, time_stamp,\n                                                   text_input, get_text_template, i,video_prefix,gathered_information_JSON)\n        tasks.append(task)"
        },
        {
            "comment": "The code defines a class ScreenClassification that takes input example, template, and llm_provider as parameters. It has an _pre method which takes optional input and screenshot_file as parameters and returns them. The get_completion_in_sequence function waits for 2 seconds before gathering information using llm_provider and returns True.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":131-157",
            "content": "        # wait 2 seconds for the next request\n        time.sleep(2)\n    return await asyncio.gather(*tasks)\ndef get_completion_in_sequence(llm_provider, text_input_map, extracted_frame_paths, text_input,get_text_template,video_prefix,gathered_information_JSON):\n    for i, (current_frame_path, time_stamp) in enumerate(extracted_frame_paths):\n        gather_information_get_completion_sequence(llm_provider, text_input_map, current_frame_path, time_stamp,\n                                                   text_input, get_text_template, i,video_prefix,gathered_information_JSON)\n    return True\nclass ScreenClassification():\n    def __init__(self,\n                 input_example: Dict = None,\n                 template: Dict = None,\n                 llm_provider: LLMProvider = None,\n                 ):\n        self.input_example = input_example\n        self.template = template\n        self.llm_provider = llm_provider\n    def _pre(self, *args, input=None, screenshot_file=None, **kwargs):\n        return input, screenshot_file"
        },
        {
            "comment": "The code contains a class named \"ScreenClassification\" that is not implemented yet. It has an unimplemented method \"__call__\". The file also includes the class \"GatherInformation\", which requires various inputs such as input_map, template, icon_replacer, etc., and provides a method \"_pre\" for preprocessing.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":159-189",
            "content": "    def __call__(self, *args, input=None, screenshot_file=None, **kwargs):\n        raise NotImplementedError('ScreenClassification is not implemented independently yet')\n    def _post(self, *args, data=None, **kwargs):\n        return data\nclass GatherInformation():\n    def __init__(self,\n                 input_map: Dict = None,\n                 template: str = None,\n                 icon_replacer: Any = None,\n                 object_detector: Any = None,\n                 llm_provider: LLMProvider = None,\n                 text_input_map: Dict = None,\n                 get_text_template: str = None,\n                 frame_extractor: Any = None\n                 ):\n        self.input_map = input_map\n        self.template = template\n        self.icon_replacer = icon_replacer\n        self.object_detector = object_detector\n        self.llm_provider = llm_provider\n        self.text_input_map = text_input_map\n        self.get_text_template = get_text_template\n        self.frame_extractor = frame_extractor\n    def _pre(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:"
        },
        {
            "comment": "The code is a part of a planner class. It takes an input dictionary, gathers information based on the given configurations and uses a frame extractor to gather information if specified in the configuration. It also checks for image files in the input and processes the response.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":190-220",
            "content": "        return input\n    def __call__(self, *args, input: Dict[str, Any] = None, class_=None, **kwargs) -> Dict[str, Any]:\n        gather_infromation_configurations = input[\"gather_information_configurations\"]\n        frame_extractor_gathered_information = None\n        icon_replacer_gathered_information = None\n        object_detector_gathered_information = None\n        llm_description_gathered_information = None\n        input = self.input_map if input is None else input\n        input = self._pre(input=input)\n        image_files = []\n        if \"image_introduction\" in input.keys():\n            for image_info in input[\"image_introduction\"]:\n                image_files.append(image_info[\"path\"])\n        flag = True\n        processed_response = {}\n        # Gather information by frame extractor\n        if gather_infromation_configurations[\"frame_extractor\"] is True:\n            logger.write(f\"Using frame extractor to gather information\")\n            if self.frame_extractor is not None:\n                text_input = input[\"text_input\"]"
        },
        {
            "comment": "This code segment handles video information gathering for the planner. If an offline test is specified, it uses provided frame paths. Otherwise, it extracts frames using `frame_extractor` and applies `icon_replacer` if configured to gather information. Exceptions are logged for any errors during processing.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":221-238",
            "content": "                video_path = input[\"video_clip_path\"]\n                if \"test_text_image\" in input.keys() and input[\"test_text_image\"]:  # offline test\n                    extracted_frame_paths = input[\"test_text_image\"]\n                else:  # online run\n                    # extract the text information of the whole video\n                    # run the frame_extractor to get the key frames\n                    extracted_frame_paths = self.frame_extractor.extract(video_path=video_path)\n                # Gather information by Icon replacer\n                if gather_infromation_configurations[\"icon_replacer\"] is True:\n                    logger.write(f\"Using icon replacer to gather information\")\n                    if self.icon_replacer is not None:\n                        try:\n                            extracted_frame_paths = self._replace_icon(extracted_frame_paths)\n                        except Exception as e:\n                            logger.error(f\"Error in gather information by Icon replacer: {e}\")"
        },
        {
            "comment": "This code sets a flag to False if the Icon replacer is not set, and then skips gathering information by Icon replacer. It also gathers text information from the whole video in parallel using asyncio event loop and runs until completion with get_completion_in_parallel function.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":239-257",
            "content": "                            flag = False\n                    else:\n                        logger.warn('Icon replacer is not set, skipping gather information by Icon replacer')\n                # For each keyframe, use llm to get the text information\n                video_prefix = os.path.basename(video_path).split('.')[0].split('_')[-1]  # Different video should have differen prefix for avoiding the same time stamp\n                frame_extractor_gathered_information = JSONStructure()\n                if config.parallel_request_gather_information:\n                    # Create completions in parallel\n                    logger.write(f\"Start gathering text information from the whole video in parallel\")\n                    loop = asyncio.new_event_loop()\n                    asyncio.set_event_loop(loop)\n                    try:\n                        loop.run_until_complete(\n                            get_completion_in_parallel(self.llm_provider, self.text_input_map, extracted_frame_paths,\n            "
        },
        {
            "comment": "The code is handling user interrupts by cancelling any running tasks and closing the loop. If not interrupted, it starts gathering text information from the whole video sequence using a separate function get_completion_in_sequence(). Finally, it sorts the gathered information by timestamp and logs that the process has finished.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":257-275",
            "content": "                                           text_input,self.get_text_template,video_prefix,frame_extractor_gathered_information))\n                    except KeyboardInterrupt:\n                        tasks = [t for t in asyncio.all_tasks() if t is not asyncio.current_task()]\n                        for task in tasks:\n                            task.cancel()\n                        loop.run_until_complete(asyncio.gather(*tasks, return_exceptions=True))\n                    finally:\n                        loop.close()\n                else:\n                    logger.write(f\"Start gathering text information from the whole video in sequence\")\n                    get_completion_in_sequence(self.llm_provider, self.text_input_map, extracted_frame_paths,\n                                               text_input,self.get_text_template,video_prefix,frame_extractor_gathered_information)\n                frame_extractor_gathered_information.sort_index_by_timestamp()\n                logger.write(f\"Finish gathering text information from the whole video\")"
        },
        {
            "comment": "Code handles the case when FrameExtractor is not set. If FrameExtractor is not set, it logs a warning message and sets frame_extractor_gathered_information to None. It then checks if there is any gathered_information_JSON. If present, it extracts dialogue information from it. If no JSON or FrameExtractor is available, it logs another warning and sets dialogues as an empty list. Finally, it updates the task_description using all_task_guidance.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":277-294",
            "content": "            else:\n                logger.warn('Frame extractor is not set, skipping gather information by frame extractor')\n                frame_extractor_gathered_information = None\n            # Get dialogue information from the gathered_information_JSON at the subfounder find the dialogue frames\n            if frame_extractor_gathered_information is not None:\n                dialogues = [item[\"values\"] for item in frame_extractor_gathered_information.search_type_across_all_indices(\"dialogue\")]\n            else:\n                if self.frame_extractor is not None:\n                    msg = \"No gathered_information_JSON received, so no dialogue information is provided.\"\n                else:\n                    msg = \"No gathered_information_JSON available, no Frame Extractor in use.\"\n                logger.warn(msg)\n                dialogues = []\n            # Update the <$task_description$> in the gather_information template with the latest task_description\n            all_task_guidance = frame_extractor_gathered_information.search_type_across_all_indices(constants.TASK_GUIDANCE)"
        },
        {
            "comment": "This code removes \"none\" task guidance, selects the latest non-none task guidance if available, stores it in last_task_guidance and assigns it to input for gathering information. It then uses LLM description to assemble prompts for the LLM provider.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":296-313",
            "content": "            # Remove the content of \"task is none\"\n            all_task_guidance = [task_guidance for task_guidance in all_task_guidance if constants.NONE_TASK_OUTPUT not in task_guidance[\"values\"].lower()]\n            if len(all_task_guidance) != 0:\n                # New task guidance is found, use the latest one\n                last_task_guidance = max(all_task_guidance, key=lambda x: x['index'])['values']\n                input[constants.TASK_DESCRIPTION] = last_task_guidance # this is for the input of the gather_information\n            # @TODO: summary the dialogue and use it\n        # Gather information by LLM provider\n        if gather_infromation_configurations[\"llm_description\"] is True:\n            logger.write(f\"Using llm description to gather information\")\n            try:\n                # Call the LLM provider for gather information json\n                message_prompts = self.llm_provider.assemble_prompt(template_str=self.template, params=input)\n                logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')"
        },
        {
            "comment": "This code continuously retries to gather information until a valid response is obtained, then processes the response and stores it in llm_description_gathered_information.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":315-335",
            "content": "                gather_information_success_flag = False\n                while gather_information_success_flag is False:\n                    try:\n                        response, info = self.llm_provider.create_completion(message_prompts)\n                        logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n                        # Convert the response to dict\n                        processed_response = parse_semi_formatted_text(response)\n                        gather_information_success_flag = True\n                    except Exception as e:\n                        logger.error(f\"Response of image description is not in the correct format: {e}, retrying...\")\n                        gather_information_success_flag = False\n                        # Wait 2 seconds for the next request and retry\n                        time.sleep(2)\n                llm_description_gathered_information = processed_response\n            except Exception as e:\n                logger.error(f\"Error in gather image description information: {e}\")"
        },
        {
            "comment": "Flag checks if any information was gathered. If flag is True, combines \"objects\" from multiple sources and removes duplicates. Adds unique objects to processed_response and includes gathered_information_JSON. Checks if task guidance list is empty.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":336-357",
            "content": "                flag = False\n        # Assemble the gathered_information_JSON\n        if flag:\n            objects = []\n            if icon_replacer_gathered_information is not None and \"objects\" in icon_replacer_gathered_information:\n                objects.extend(icon_replacer_gathered_information[\"objects\"])\n            if object_detector_gathered_information is not None and \"objects\" in object_detector_gathered_information:\n                objects.extend(object_detector_gathered_information[\"objects\"])\n            if llm_description_gathered_information is not None and \"objects\" in llm_description_gathered_information:\n                objects.extend(llm_description_gathered_information[\"objects\"])\n            objects = list(set(objects))\n            processed_response[\"objects\"] = objects\n            # Merge the gathered_information_JSON to the processed_response\n            processed_response[\"gathered_information_JSON\"] = frame_extractor_gathered_information\n            if len(all_task_guidance) == 0:"
        },
        {
            "comment": "The code sets the last task guidance value in the processed response if it exists, otherwise leaves it empty. It then uses object detector to gather information by checking if the configuration allows it and if the object detector is not None. It detects objects in an image using the object detector, setting the target object name based on the response and applying a box threshold of 0.4. Finally, it utilizes the 'cuda' device for detection.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":358-372",
            "content": "                processed_response[constants.LAST_TASK_GUIDANCE] = \"\"\n            else:\n                processed_response[constants.LAST_TASK_GUIDANCE] = last_task_guidance\n        # Gather information by object detector, which is grounding dino.\n        if gather_infromation_configurations[\"object_detector\"] is True:\n            logger.write(f\"Using object detector to gather information\")\n            if self.object_detector is not None:\n                try:\n                    target_object_name = processed_response[constants.TARGET_OBJECT_NAME].lower() \\\n                        if constants.NONE_TARGET_OBJECT_OUTPUT not in processed_response[constants.TARGET_OBJECT_NAME].lower() else \"\"\n                    image_source, boxes, logits, phrases = self.object_detector.detect(image_path=image_files[0],\n                                                                                       text_prompt= target_object_name,\n                                                                                       box_threshold=0.4, device='cuda')"
        },
        {
            "comment": "Function collects object detection results and updates a response dictionary. In case of exception, logs the error and sets flag to False. Retrieves minimap object detection data and adds it to the response dictionary. Finally, checks success and returns a combined dictionary with flag, success, input, and processed response.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":373-403",
            "content": "                    processed_response[\"boxes\"] = boxes\n                    processed_response[\"logits\"] = logits\n                    processed_response[\"phrases\"] = phrases\n                except Exception as e:\n                    logger.error(f\"Error in gather information by object detector: {e}\")\n                    flag = False\n                try:\n                    minimap_detection_objects = self.object_detector.process_minimap_targets(image_files[0])\n                    processed_response.update({constants.MINIMAP_INFORMATION:minimap_detection_objects})\n                except Exception as e:\n                    logger.error(f\"Error in gather information by object detector for minimap: {e}\")\n                    flag = False\n        success = self._check_success(data=processed_response)\n        data = dict(\n            flag=flag,\n            success=success,\n            input=input,\n            res_dict=processed_response,\n        )\n        data = self._post(data=data)\n        return data\n    def _post(self, *args, data: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:"
        },
        {
            "comment": "The code defines a class `DecisionMaking` with an initialization function that takes input map, template, and LLMProvider as parameters. The class contains a method `_pre` which returns a dictionary after processing the inputs. There is also a helper function `_check_success` to check if the description is present in the given data and `_replace_icon` to replace the icons from extracted frame paths.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":404-439",
            "content": "        return data\n    def _check_success(self, *args, data, **kwargs):\n        success = False\n        prop_name = \"description\"\n        if prop_name in data.keys():\n            desc = data[prop_name]\n            success = desc is not None and len(desc) > 0\n        return success\n    def _replace_icon(self, extracted_frame_paths):\n        extracted_frames = [frame[0] for frame in extracted_frame_paths]\n        extracted_timesteps = [frame[1] for frame in extracted_frame_paths]\n        extracted_frames = self.icon_replacer(image_paths=extracted_frames)\n        extracted_frame_paths = list(zip(extracted_frames, extracted_timesteps))\n        return extracted_frame_paths\nclass DecisionMaking():\n    def __init__(self,\n                 input_map: Dict = None,\n                 template: Dict = None,\n                 llm_provider: LLMProvider = None,\n                 ):\n        self.input_map = input_map\n        self.template = template\n        self.llm_provider = llm_provider\n    def _pre(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:"
        },
        {
            "comment": "The code defines a method for a class that takes an input, preprocesses it, and then uses an LLM (Language Model) provider to make a decision based on the input. The result is converted into a dictionary format and returned. If no response is received or the response is empty, a warning message is logged. Exceptions are caught and handled through logging.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":440-469",
            "content": "        return input\n    def __call__(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        input = self.input_map if input is None else input\n        input = self._pre(input=input)\n        flag = True\n        processed_response = {}\n        try:\n            message_prompts = self.llm_provider.assemble_prompt(template_str=self.template, params=input)\n            logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n            # Call the LLM provider for decision making\n            response, info = self.llm_provider.create_completion(message_prompts)\n            logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n            if response is None or len(response) == 0:\n                logger.warn('No response in decision making call')\n                logger.debug(input)\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n        except Exception as e:\n            logger.error(f\"Error in decision_making: {e}\")"
        },
        {
            "comment": "This code snippet defines a class called `SuccessDetection` which takes an input map, template, and LLMProvider as parameters. The `_pre` method preprocesses the input before it is passed to the `__call__` method. Inside `__call__`, the input is further processed using the input map or the provided input, and then passed to the LLM provider for success detection. If an exception occurs during this process, it is logged as an error. The function returns a dictionary with flag, input, and processed response (res_dict) fields. Additionally, there is a `_post` method that takes data as input and returns it.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":470-512",
            "content": "            logger.error_ex(e)\n            flag = False\n        data = dict(\n            flag=flag,\n            input=input,\n            res_dict=processed_response,\n        )\n        data = self._post(data=data)\n        return data\n    def _post(self, *args, data: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return data\nclass SuccessDetection():\n    def __init__(self,\n                 input_map: Dict = None,\n                 template: Dict = None,\n                 llm_provider: LLMProvider = None,\n                 ):\n        self.input_map = input_map\n        self.template = template\n        self.llm_provider = llm_provider\n    def _pre(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return input\n    def __call__(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        input = self.input_map if input is None else input\n        input = self._pre(input=input)\n        flag = True\n        processed_response = {}\n        try:\n            # Call the LLM provider for success detection"
        },
        {
            "comment": "The code appears to be a part of an AI planner that utilizes a LLM (Large Language Model) provider. It assembles prompts, creates completions based on those prompts, converts the response to a dictionary format and sends the data to a post method for further processing. An exception handling block is also present to handle any errors that may occur during execution.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":513-547",
            "content": "            message_prompts = self.llm_provider.assemble_prompt(template_str=self.template, params=input)\n            logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n            response, info = self.llm_provider.create_completion(message_prompts)\n            logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n        except Exception as e:\n            logger.error(f\"Error in success_detection: {e}\")\n            flag = False\n        data = dict(\n            flag=flag,\n            input=input,\n            res_dict=processed_response,\n        )\n        data = self._post(data=data)\n        return data\n    def _post(self, *args, data: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return data\nclass SelfReflection():\n    def __init__(self,\n                 input_map: Dict = None,\n                 template: Dict = None,\n                 llm_provider: LLMProvider = None,"
        },
        {
            "comment": "This code defines a class with an input map, template, and LLM provider as parameters. It has two methods: _pre() and __call__(). The _pre() method prepares the input for processing. The __call__() method uses the input_map to get the input, then applies _pre(), calls llm_provider to generate a prompt, logs the prompts, then creates a completion using llm_provider. Finally, it parses the response into a dictionary.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":548-580",
            "content": "                 ):\n        self.input_map = input_map\n        self.template = template\n        self.llm_provider = llm_provider\n    def _pre(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return input\n    def __call__(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        input = self.input_map if input is None else input\n        input = self._pre(input=input)\n        flag = True\n        processed_response = {}\n        try:\n            # Call the LLM provider for self reflection\n            message_prompts = self.llm_provider.assemble_prompt(template_str=self.template, params=input)\n            logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n            response, info = self.llm_provider.create_completion(message_prompts)\n            logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n        except Exception as e:"
        },
        {
            "comment": "The code defines a function that handles errors and calls another method to post data. It also initializes an InformationSummary class with input_map, template, and llm_provider as parameters, and includes methods for preprocessing input and processing the summary.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":581-622",
            "content": "            logger.error(f\"Error in self reflection: {e}\")\n            flag = False\n        data = dict(\n            flag=flag,\n            input=input,\n            res_dict=processed_response,\n        )\n        data = self._post(data=data)\n        return data\n    def _post(self, *args, data: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return data\nclass InformationSummary():\n    def __init__(self,\n                 input_map: Dict = None,\n                 template: Dict = None,\n                 llm_provider: LLMProvider = None,\n                 ):\n        self.input_map = input_map\n        self.template = template\n        self.llm_provider = llm_provider\n    def _pre(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return input\n    def __call__(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        input = self.input_map if input is None else input\n        input = self._pre(input=input)\n        flag = True\n        processed_response = {}\n        res_json = None"
        },
        {
            "comment": "The code attempts to assemble a prompt using the LLM (Large Language Model) provider and then create a completion. If any exception occurs, it logs an error message. The response is parsed into a dictionary format, and a data object is created with flag, input, and processed response information. Finally, the _post method is called to process the data.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":624-659",
            "content": "        try:\n            # Call the LLM provider for information summary\n            message_prompts = self.llm_provider.assemble_prompt(template_str=self.template, params=input)\n            logger.debug(f'{logger.UPSTREAM_MASK}{json.dumps(message_prompts, ensure_ascii=False)}\\n')\n            response, info = self.llm_provider.create_completion(message_prompts)\n            logger.debug(f'{logger.DOWNSTREAM_MASK}{response}\\n')\n            # Convert the response to dict\n            processed_response = parse_semi_formatted_text(response)\n        except Exception as e:\n            logger.error(f\"Error in information_summary: {e}\")\n            flag = False\n        data = dict(\n            flag=flag,\n            input=input,\n            res_dict=processed_response,\n            # res_json=res_json,\n        )\n        data = self._post(data=data)\n        return data\n    def _post(self, *args, data: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        return data\nclass Planner(BasePlanner):\n    def __init__(self,"
        },
        {
            "comment": "This code defines a function that takes input key-value pairs and templates. It utilizes several parameters, such as llm_provider, planner_params, use_screen_classification, use_information_summary, use_self_reflection, gather_information_max_steps, icon_replacer, object_detector, and frame_extractor. The function uses these parameters to compose a prompt for a task, with planner_params specifying the task steps and prompt paths for inputs based on the given parameters.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":660-685",
            "content": "                 llm_provider: Any = None,\n                 planner_params: Dict = None,\n                 use_screen_classification: bool = False,\n                 use_information_summary: bool = False,\n                 use_self_reflection: bool = False,\n                 gather_information_max_steps: int = 1,  # 5,\n                 icon_replacer: Any = None,\n                 object_detector: Any = None,\n                 frame_extractor: Any = None,\n                 ):\n        \"\"\"\n        inputs: input key-value pairs\n        templates: template for composing the prompt\n        planner_params = {\n            \"__check_list__\":[\n              \"screen_classification\",\n              \"gather_information\",\n              \"decision_making\",\n              \"information_summary\",\n              \"self_reflection\"\n            ],\n            \"prompt_paths\": {\n              \"inputs\": {\n                \"screen_classification\": \"./res/prompts/inputs/screen_classification.json\",\n                \"gather_information\": \"./res/prompts/inputs/gather_information.json\","
        },
        {
            "comment": "This code sets up a planner with input prompts and template files for decision making, success detection, information summary, and self-reflection tasks. The llm_provider is initialized in the superclass constructor.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":686-705",
            "content": "                \"decision_making\": \"./res/prompts/inputs/decision_making.json\",\n                \"success_detection\": \"./res/prompts/inputs/success_detection.json\",\n                \"information_summary\": \"./res/prompts/inputs/information_summary.json\",\n                \"self_reflection\": \"./res/prompts/inputs/self_reflection.json\",\n              },\n              \"templates\": {\n                \"screen_classification\": \"./res/prompts/templates/screen_classification.prompt\",\n                \"gather_information\": \"./res/prompts/templates/gather_information.prompt\",\n                \"decision_making\": \"./res/prompts/templates/decision_making.prompt\",\n                \"success_detection\": \"./res/prompts/templates/success_detection.prompt\",\n                \"information_summary\": \"./res/prompts/templates/information_summary.prompt\",\n                \"self_reflection\": \"./res/prompts/templates/self_reflection.prompt\",\n              }\n            }\n          }\n        \"\"\"\n        super(BasePlanner, self).__init__()\n        self.llm_provider = llm_provider"
        },
        {
            "comment": "The code defines a class with several instance variables for different features such as screen classification, information summary, and self-reflection. It also sets the maximum steps for gathering information. The `set_internal_params` method allows reconfiguration of the planner with optional parameters. Additionally, it checks the validity of planner_params using the `check_planner_params` function to avoid any potential errors.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":707-728",
            "content": "        self.use_screen_classification = use_screen_classification\n        self.use_information_summary = use_information_summary\n        self.use_self_reflection = use_self_reflection\n        self.gather_information_max_steps = gather_information_max_steps\n        self.icon_replacer = icon_replacer\n        self.object_detector = object_detector\n        self.frame_extractor = frame_extractor\n        self.set_internal_params(planner_params=planner_params,\n                                 use_screen_classification=use_screen_classification,\n                                 use_information_summary=use_information_summary)\n    # Allow re-configuring planner\n    def set_internal_params(self,\n                            planner_params: Dict = None,\n                            use_screen_classification: bool = False,\n                            use_information_summary: bool = False):\n        self.planner_params = planner_params\n        if not check_planner_params(self.planner_params):\n            raise ValueError(f\"Error in planner_params: {self.planner_params}\")"
        },
        {
            "comment": "This code initializes instance attributes for a planner object. It sets the inputs and templates, checks a boolean flag to initialize screen_classification_, and initializes gather_information_. The input examples and templates are used in these process steps. If the use_screen_classification flag is true, an instance of ScreenClassification is initialized; otherwise, it's set to None. Similarly, an instance of GatherInformation is created based on the given inputs and templates. FrameExtractor appears to be used by both steps.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":730-744",
            "content": "        self.inputs = self._init_inputs()\n        self.templates = self._init_templates()\n        if use_screen_classification:\n            self.screen_classification_ = ScreenClassification(input_example=self.inputs[\"screen_classification\"],\n                                                               template=self.templates[\"screen_classification\"],\n                                                               llm_provider=self.llm_provider)\n        else:\n            self.screen_classification_ = None\n        self.gather_information_ = GatherInformation(input_map=self.inputs[\"gather_information\"],\n                                                     template=self.templates[\"gather_information\"],\n                                                     text_input_map=self.inputs[\"gather_text_information\"],\n                                                     get_text_template=self.templates[\"gather_text_information\"],\n                                                     frame_extractor=self.frame_extractor,"
        },
        {
            "comment": "The code is creating and initializing several modules (icon_replacer, object_detector, decision_making, success_detection, self_reflection) with different input maps and templates. The llm_provider seems to be a shared parameter across these modules.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":745-759",
            "content": "                                                     icon_replacer=self.icon_replacer,\n                                                     object_detector=self.object_detector,\n                                                     llm_provider=self.llm_provider)\n        self.decision_making_ = DecisionMaking(input_map=self.inputs[\"decision_making\"],\n                                               template=self.templates[\"decision_making\"],\n                                               llm_provider=self.llm_provider)\n        self.success_detection_ = SuccessDetection(input_map=self.inputs[\"success_detection\"],\n                                                   template=self.templates[\"success_detection\"],\n                                                   llm_provider=self.llm_provider)\n        if self.use_self_reflection:\n            self.self_reflection_ = SelfReflection(input_map=self.inputs[\"self_reflection\"],\n                                                   template=self.templates[\"self_reflection\"],"
        },
        {
            "comment": "This code initializes the self-reflection and information summary attributes based on input parameters. It also initializes input examples by assembling paths from a JSON file and reading resource files, and then initializes templates using these example inputs.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":760-788",
            "content": "                                                   llm_provider=self.llm_provider)\n        else:\n            self.self_reflection_ = None\n        if use_information_summary:\n            self.information_summary_ = InformationSummary(input_map=self.inputs[\"information_summary\"],\n                                                           template=self.templates[\"information_summary\"],\n                                                           llm_provider=self.llm_provider)\n        else:\n            self.information_summary_ = None\n    def _init_inputs(self):\n        input_examples = dict()\n        prompt_paths = self.planner_params[\"prompt_paths\"]\n        input_example_paths = prompt_paths[\"inputs\"]\n        for key, value in input_example_paths.items():\n            path = assemble_project_path(value)\n            if path.endswith(PROMPT_EXT):\n                input_examples[key] = read_resource_file(path)\n            else:\n                input_examples[key] = load_json(path)\n        return input_examples\n    def _init_templates(self):"
        },
        {
            "comment": "The code defines a function `gather_information` that takes an input dictionary and returns another dictionary after processing it. It first checks if the input is provided, then retrieves the image file path from it. Depending on the value of `use_screen_classification`, it assigns the class to either the result of `screen_classification_` function or None. The code then loops for a maximum number of steps (`gather_information_max_steps`) and calls the `gather_information_` function with the input and class as arguments. It retrieves the success status from the returned data and continues if successful.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":790-821",
            "content": "        templates = dict()\n        prompt_paths = self.planner_params[\"prompt_paths\"]\n        template_paths = prompt_paths[\"templates\"]\n        for key, value in template_paths.items():\n            path = assemble_project_path(value)\n            if path.endswith(PROMPT_EXT):\n                templates[key] = read_resource_file(path)\n            else:\n                templates[key] = load_json(path)\n        return templates\n    def gather_information(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        if input is None:\n            input = self.inputs[\"gather_information\"]\n        image_file = input[\"image_introduction\"][0][\"path\"]\n        if self.use_screen_classification:\n            class_ = self.screen_classification_(screenshot_file=image_file)[\"class_\"]\n        else:\n            class_ = None\n        for i in range(self.gather_information_max_steps):\n            data = self.gather_information_(input=input, class_=class_)\n            success = data[\"success\"]\n            if success:"
        },
        {
            "comment": "This code snippet contains several methods: decision_making, success_detection, self_reflection, and information_summary. These methods take an optional input dictionary and return a Dict[str, Any] data type. The first if statement checks if the input parameter is None and assigns it to the corresponding input value from the instance's inputs dictionary. This allows for default inputs when no specific input is provided. Each method then proceeds to call its respective method with the input argument.",
            "location": "\"/media/root/Prima/works/github_code/Cradle/docs/src/cradle/planner/planner.py\":822-864",
            "content": "                break\n        return data\n    def decision_making(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        if input is None:\n            input = self.inputs[\"decision_making\"]\n        data = self.decision_making_(input=input)\n        return data\n    def success_detection(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        if input is None:\n            input = self.inputs[\"success_detection\"]\n        data = self.success_detection_(input=input)\n        return data\n    def self_reflection(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        if input is None:\n            input = self.inputs[\"self_reflection\"]\n        data = self.self_reflection_(input=input)\n        return data\n    def information_summary(self, *args, input: Dict[str, Any] = None, **kwargs) -> Dict[str, Any]:\n        if input is None:\n            input = self.inputs[\"information_summary\"]\n        data = self.information_summary_(input=input)\n        return data"
        }
    ]
}